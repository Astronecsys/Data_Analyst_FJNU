{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只使用close预测\n",
    "找到最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Desktop\\学业\\第五学期课业\\数据分析\\Data_Analyst_FJNU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "while os.getcwd().split('\\\\')[-1] != \"Data_Analyst_FJNU\":\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shelt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(code):\n",
    "    stock_data =  pd.read_csv(f'./Data/history_A_stock_k_data/{code}.csv')\n",
    "    stock_data = stock_data[['date','close']]\n",
    "    stock_data['date'] = pd.to_datetime(stock_data['date'])\n",
    "    stock_data.set_index('date',inplace=True)\n",
    "    return stock_data\n",
    "\n",
    "def plot_dataframe(df):\n",
    "    plt.plot(df.index, df['close'])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close')\n",
    "    plt.title('DataFrame Plot')\n",
    "    plt.show()\n",
    "    \n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y, indices = [], [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data.iloc[i:i+sequence_length])\n",
    "        y.append(data.iloc[i+sequence_length])\n",
    "        indices.append(data.index[i+sequence_length])\n",
    "    return np.array(X), np.array(y), indices\n",
    "\n",
    "def build_model(units, LSTM_layers, Dense_layers, X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    for _ in range(LSTM_layers):\n",
    "        model.add(LSTM(units=units, return_sequences=True))\n",
    "        model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    for _ in range(Dense_layers):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shelt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shelt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 15, 16)            1152      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 16)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 15, 16)            2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 16)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5665 (22.13 KB)\n",
      "Trainable params: 5665 (22.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "./Data/model/sh.600019/{val_loss:.8f}_{epoch:02d}_dim_15_units_16_lstm_1_dense_1.h5\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Shelt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shelt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "157/157 [==============================] - 9s 20ms/step - loss: 0.0050 - mean_absolute_error: 0.0416 - val_loss: 7.4250e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.0023 - mean_absolute_error: 0.0281 - val_loss: 6.3442e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0019 - mean_absolute_error: 0.0259 - val_loss: 8.6125e-04 - val_mean_absolute_error: 0.0229\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0015 - mean_absolute_error: 0.0240 - val_loss: 5.8263e-04 - val_mean_absolute_error: 0.0159\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.0016 - mean_absolute_error: 0.0239 - val_loss: 6.6800e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.0014 - mean_absolute_error: 0.0235 - val_loss: 7.7278e-04 - val_mean_absolute_error: 0.0220\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0013 - mean_absolute_error: 0.0226 - val_loss: 4.2823e-04 - val_mean_absolute_error: 0.0138\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0012 - mean_absolute_error: 0.0219 - val_loss: 5.1487e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0214 - val_loss: 3.8247e-04 - val_mean_absolute_error: 0.0134\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0216 - val_loss: 3.5612e-04 - val_mean_absolute_error: 0.0136\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 16)            1152      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30, 16)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 16)            2112      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 30, 16)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5665 (22.13 KB)\n",
      "Trainable params: 5665 (22.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "./Data/model/sh.600019/{val_loss:.8f}_{epoch:02d}_dim_30_units_16_lstm_1_dense_1.h5\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 10s 31ms/step - loss: 0.0054 - mean_absolute_error: 0.0433 - val_loss: 0.0019 - val_mean_absolute_error: 0.0337\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.0027 - mean_absolute_error: 0.0310 - val_loss: 8.1067e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.0018 - mean_absolute_error: 0.0257 - val_loss: 5.7539e-04 - val_mean_absolute_error: 0.0166\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.0019 - mean_absolute_error: 0.0257 - val_loss: 6.8560e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0015 - mean_absolute_error: 0.0242 - val_loss: 5.4459e-04 - val_mean_absolute_error: 0.0160\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.0015 - mean_absolute_error: 0.0235 - val_loss: 4.4414e-04 - val_mean_absolute_error: 0.0155\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0013 - mean_absolute_error: 0.0230 - val_loss: 4.4060e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0012 - mean_absolute_error: 0.0215 - val_loss: 4.0684e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0011 - mean_absolute_error: 0.0208 - val_loss: 3.3650e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0014 - mean_absolute_error: 0.0227 - val_loss: 4.7865e-04 - val_mean_absolute_error: 0.0158\n"
     ]
    }
   ],
   "source": [
    "# dimension = 50\n",
    "# units = 32\n",
    "# LSTM_layers = 2\n",
    "# Dense_layers = 2\n",
    "code = 'sh.600019'\n",
    "model_dir = f'./Data/model/{code}'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "# dimension_list = [15, 30, 50]\n",
    "# units_list = [16, 32, 64]\n",
    "# LSTM_layers_list = [1,2,3]\n",
    "# Dense_layers_list = [1,2,3]\n",
    "dimension_list = [15, 30]\n",
    "units_list = [16]\n",
    "LSTM_layers_list = [1]\n",
    "Dense_layers_list = [1]\n",
    "df = get_stock_data('sh.600019')\n",
    "for dimension in dimension_list:\n",
    "    X, y, indices = create_sequences(df['close'], dimension)\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = scaler.fit_transform(y.reshape(-1, 1))\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(X, y, indices, test_size=0.1, random_state=42, shuffle=False)\n",
    "    for units in units_list:\n",
    "        for LSTM_layers in LSTM_layers_list:\n",
    "            for Dense_layers in Dense_layers_list:\n",
    "                model = build_model(units, LSTM_layers, Dense_layers,X_train, y_train)\n",
    "                early_stopping = EarlyStopping(\n",
    "                    monitor='val_loss', \n",
    "                    patience=10, \n",
    "                    restore_best_weights=True\n",
    "                )\n",
    "                model_file = f\"{model_dir}/\"+\"{val_loss:.8f}_{epoch:02d}\"+f\"_dim_{dimension}_units_{units}_lstm_{LSTM_layers}_dense_{Dense_layers}.h5\"\n",
    "                print(model_file)\n",
    "                checkpoint = ModelCheckpoint(\n",
    "                    filepath = model_file,\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_loss',        \n",
    "                    save_best_only=True,         \n",
    "                    mode='min',       \n",
    "                )\n",
    "                history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x94 in position 19: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 2\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/model/sh.600019/0.00033650_09_dim_30_units_16_lstm_1_dense_1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mIsDirectory(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x94 in position 19: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_model = load_model('./Data/model/sh.600019/0.00033650_09_dim_30_units_16_lstm_1_dense_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaludate(model,X,y):\n",
    "    loss, mean_absolute_error = model.evaluate(X,y)\n",
    "    print(f'Test Loss: {loss}, Test Mean Absolute Error: {mean_absolute_error}')\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "# evaludate(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_show(X_test, indices):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_actual = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    result_df = pd.DataFrame({'Date': indices, 'Predicted': y_pred_actual.flatten()})\n",
    "    result_df.index = pd.to_datetime(result_df.index)\n",
    "    result_df.set_index('Date', inplace=True)\n",
    "    result_df.sort_index(inplace=True)\n",
    "\n",
    "    # plot\n",
    "    # scatter\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(result_df.index, result_df['Predicted'], label='Predicted', color='red')\n",
    "    plt.plot(df.index, df['close'], label='Actual', color='blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.title('Actual vs Predicted Stock Prices')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    recent_month_data = result_df[result_df.index >= result_df.index.max() - pd.DateOffset(months=12)]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(recent_month_data.index, recent_month_data['Predicted'], label='Predicted', color='red')\n",
    "    plt.plot(df.index[-30*12:], df['close'].tail(30*12), label='Actual', color='blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.title('Actual vs Predicted Stock Prices (Most Recent Month)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(result_df.tail(5))\n",
    "# predict_show(X_test, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_show(X[-1098:],df.index[-1098:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_show(X,df.index[dimension:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_show(X[-2:],df.index[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(model, df):\n",
    "    last_sequence = df.iloc[-dimension:].values\n",
    "    last_sequence = scaler.transform(last_sequence)\n",
    "    last_sequence = last_sequence.transpose()\n",
    "    predicted_value = model.predict(last_sequence)\n",
    "    predicted_value = scaler.inverse_transform(predicted_value)\n",
    "    last_date = df.index[-1]\n",
    "    result_data = {'close': predicted_value[0]}\n",
    "    result_date = last_date + pd.DateOffset(days=1)\n",
    "    result_df = pd.DataFrame(result_data, index=[result_date])\n",
    "    new_df = pd.concat([df, result_df], axis=0)\n",
    "    return new_df\n",
    "# new_df = df\n",
    "# new_df = predict_next(model, new_df)\n",
    "# new_df.tail()\n",
    "# new_df = predict_next(model, new_df)\n",
    "# new_df.tail()\n",
    "# new_df = predict_next(model, new_df)\n",
    "# new_df.tail()\n",
    "# new_df = predict_next(model, new_df)\n",
    "# new_df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
